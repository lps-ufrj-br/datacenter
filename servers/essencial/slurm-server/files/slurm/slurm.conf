# slurm.conf file generated by configurator.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#
ClusterName=caloba
SlurmctldHost=slurm-server

#AuthAltTypes=auth/jwt
#AuthAltParameters=jwt_key=/var/spool/slurm/jwt_hs256.key

#
#DisableRootJobs=NO
#EnforcePartLimits=NO
#Epilog=
#EpilogSlurmctld=
#FirstJobId=1
#MaxJobId=999999
GresTypes=gpu
#GroupUpdateForce=0
#GroupUpdateTime=600
#JobFileAppend=0
#JobRequeue=1
#JobSubmitPlugins=1
#KillOnBadExit=0
#LaunchType=launch/slurm
#Licenses=foo*4,bar
#MailProg=/bin/mail
#MaxJobCount=5000
#MaxStepCount=40000
#MaxTasksPerNode=128
MpiDefault=none
#MpiParams=ports=#-#
#PluginDir=
#PlugStackConfig=
#PrivateData=jobs
ProctrackType=proctrack/cgroup
#Prolog=
#PrologFlags=
#PrologSlurmctld=
#PropagatePrioProcess=0
#PropagateResourceLimits=
#PropagateResourceLimitsExcept=
RebootProgram="/sbin/shutdown -r now"
ReturnToService=2
#SallocDefaultCommand=
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmctldPort=6817
SlurmdPidFile=/var/run/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/var/spool/slurm/d
SlurmUser=slurm
#SlurmdUser=root
#SrunEpilog=
#SrunProlog=
StateSaveLocation=/var/spool/slurm/ctld
SwitchType=switch/none
#TaskEpilog=
TaskPlugin=task/cgroup
#TaskProlog=
#TopologyPlugin=topology/tree
#TmpFS=/tmp
#TrackWCKey=no
#TreeWidth=
#UnkillableStepProgram=
#UsePAM=0
#
#
# TIMERS
#BatchStartTimeout=10
#CompleteWait=0
#EpilogMsgTime=2000
#GetEnvTimeout=2
#HealthCheckInterval=0
#HealthCheckProgram=
InactiveLimit=0
KillWait=30
#MessageTimeout=10
#ResvOverRun=0
MinJobAge=300
#OverTimeLimit=0
SlurmctldTimeout=120
SlurmdTimeout=300
#UnkillableStepTimeout=60
#VSizeFactor=0
Waittime=0
#
#
# SCHEDULING
#DefMemPerCPU=0
#MaxMemPerCPU=0
#SchedulerTimeSlice=30
SchedulerType=sched/backfill
SelectType=select/cons_tres
#SelectType=select/linear
SelectTypeParameters=CR_Core_Memory,CR_CORE_DEFAULT_DIST_BLOCK,CR_ONE_TASK_PER_CORE
#
#
# JOB PRIORITY
# Flags to modify priority behavior. Applicable only if PriorityType=priority/multifactor.
# - ACCRUE_ALWAYS: If set, priority age factor will be increased despite job dependencies or holds.
# - CALCULATE_RUNNING: If set, priorities will be recalculated not only for pending jobs, but also running and suspended jobs.
# - DEPTH_OBLIVIOUS: If set, priority will be calculated based similar to the normal multifactor calculation, but depth of the associations in the tree do not adversely effect their priority. This option automatically enables NO_FAIR_TREE.
# - NO_FAIR_TREE: Disables the "fair tree" algorithm, and reverts to "classic" fair share priority scheduling.
# - INCR_ONLY: If set, priority values will only increase in value. Job priority will never decrease in value.
# - MAX_TRES: If set, the weighted TRES value (e.g. TRESBillingWeights) is calculated as the MAX of individual TRES' on a node (e.g. cpus, mem, gres) plus the sum of all global TRES' (e.g. licenses).
# - NO_NORMAL_ALL: If set, all NO_NORMAL_* flags are set.
# - NO_NORMAL_ASSOC: If set, the associaton factor is not normalized against the highest association priority.
# - NO_NORMAL_PART: If set, the partition factor is not normalized against the highest partition PriorityTier
# - NO_NORMAL_QOS: If set, the QOS factor is not normalized against the highest qos priority.
# - NO_NORMAL_TRES: If set, the QOS factor is not normalized against the job's partition TRES counts.
# - SMALL_RELATIVE_TO_TIME: If set, the job's size component will be based upon not the job size alone, but the job's size divided by its time limit.
PriorityFlags=CALCULATE_RUNNING
PriorityType=priority/multifactor	# Enable multifactor priority
PriorityDecayHalfLife=7-0		# 7 days of historical usage for weighting
PriorityCalcPeriod=5			# 5 minutes interval for recalculating half-life decay
#PriorityUsageResetPeriod=
PriorityFavorSmall=NO			# NO=Larger jobs with greater priority
PriorityMaxAge=3			# After 3 days, age factor gets to maximum
#
# Weights (greater means more important)
PriorityWeightAge=1000			# Weight for age factor
PriorityWeightAssoc=10000		# Weight for association factor
PriorityWeightFairshare=1000		# Weight for fair-share factor
PriorityWeightJobSize=1000		# Weight for job size factor (see PriorityFavorSmall)
PriorityWeightPartition=0		# Weight for partition factor
PriorityWeightQOS=0			# Weight for quality of service factor
#PriorityWeightTRES=CPU=1000,Mem=1000,GRES/gpu=3000			# List of weights for TRES Type's factors
#
#
# LOGGING AND ACCOUNTING
#AccountingStorageEnforce=associations
AccountingStorageHost=slurm-server.lps.ufrj.br
#AccountingStorageLoc=
#AccountingStoragePass=
#AccountingStoragePort=
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageTRES=gres/gpu
#AccountingStorageUser=
AccountingStoreFlags=job_comment
DebugFlags=gres
JobCompHost=caloba
#JobCompLoc=
#JobCompPass=
#JobCompPort=
JobCompType=jobcomp/none
#JobCompUser=
#JobContainerType=job_container/none
JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/linux
SlurmctldDebug=info
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdDebug=info
SlurmdLogFile=/var/log/slurm/slurmd.log
#SlurmSchedLogFile=
#SlurmSchedLogLevel=
#
#
# POWER SAVE SUPPORT FOR IDLE NODES (optional)
#SuspendProgram=
#ResumeProgram=
#SuspendTimeout=
#ResumeTimeout=
#ResumeRate=
#SuspendExcNodes=
#SuspendExcParts=
#SuspendRate=
#SuspendTime=



#
# Compute nodes
#
PartitionName=cpu Nodes=caloba[10-21] Default=YES MaxTime=7-24:00:00 State=UP #OverSubscribe=FORCE:50
NodeName=caloba[10-21] CPUs=10 RealMemory=32000 Sockets=1 CoresPerSocket=10 ThreadsPerCore=1 State=UNKNOWN 



# GPU Xeon machines
PartitionName=cpu-large Nodes=caloba[50] Default=NO MaxTime=7-24:00:00 State=UP #OverSubscribe=FORCE:50
NodeName=caloba50 CPUs=48 RealMemory=120000 Sockets=1 CoresPerSocket=48 ThreadsPerCore=1 State=UNKNOWN


# GPUs
PartitionName=gpu Nodes=caloba[71-80] Default=YES MaxTime=60:00:00 State=UP
NodeName=caloba[61-62] CPUs=10 RealMemory=30000 Sockets=1 CoresPerSocket=10 ThreadsPerCore=1 State=UNKNOWN
NodeName=caloba[63-64] CPUs=8 RealMemory=30000 Sockets=1 CoresPerSocket=8 ThreadsPerCore=1 State=UNKNOWN
NodeName=caloba[93-94] CPUs=10 RealMemory=30000 Sockets=1 CoresPerSocket=10 ThreadsPerCore=1 State=UNKNOWN


